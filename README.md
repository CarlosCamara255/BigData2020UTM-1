# BigData2020UTM

..* Big Data: is the storage or data set whose volume, speed, processing are much larger than a database.

..* The importance of the data: Your data is important because if someone gets your data. You can impersonate your identity or even get your bank account and grab the money. Now that your data is already becoming digital, they have become much more important.

..* Difference between private and open data: Virtually open data is easily found while private data is not.

..* Difference between structured and unstructured data: Structured data is data that is easy to search while unstructured data is difficult to search as well as multimedia files.

..* Difference between stored and moving data:The stored data are structured and generate information and the moving data are the ones that are circulating in the network

..* Data analysis: It is responsible for examining the data in order to draw a conclusion about the information

..* Impact of data analytics: the impact it has is that companies can now earn income through data analysis

..* Different types of data analytics
-Descriptive: In a business it allows you to see the main metrics within the business. For example, gains and losses in the month, sales made, etc.
-Diagnostic: You must have the necessary tools so that the analyst can deepen the data and isolate the root cause of a problem.
-Predictive: Predictive analysis has to do with prediction. Either the probability of an event occurring in the future, the forecast of a quantifiable amount or the estimation of a point in time at which something could happen - all of them are done through predictive models.
-Prescriptive: The prescriptive model uses an understanding of what has happened, why it has happened and a variety of "what could happen" analysis to help the user determine the best course of action to take. The prescriptive analysis is usually not only with an individual action, but in fact it is a series of other actions.


..* Docker: The idea behind Docker is to create lightweight and portable containers for software applications that can be used on any machine with Docker installed, thus also facilitating the deployment or execution of the software.

..* MapReduce: it is a framework that provides a parallel and distributed data processing system and is aimed at solving problems with large data sets, so it uses the HDFS distributed file system.

..* Hoodoop: is a set of open source programs and procedures that anyone can use as the “backbone” of their Big Data operations

..* Apache Spark: The idea is that we have n machines, for example ten machines, and each of those instances will have a version of Apache Spark installed. In this way, when we have to process a large amount of data, for example a very large file, we can divide it into ten parts, and each machine will handle a tenth of the file, and in the end we will join it.

..* Lamba and Kappa: Its objective was to have a robust fault-tolerant system, both human and hardware, that was linearly scalable and that allowed writing and reading with low latency, while kappa points to "weak" Lambda Architecture and how to solve them through an evolution Your proposal is to eliminate the batch layer leaving only the streaming layer.


